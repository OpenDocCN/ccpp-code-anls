# `chatglm.cpp\tests\test_chatglm_cpp.py`

```
# å¯¼å…¥å¿…è¦çš„æ¨¡å—
from pathlib import Path

# å¯¼å…¥ chatglm_cpp æ¨¡å—å’Œ pytest æ¨¡å—
import chatglm_cpp
import pytest

# è·å–é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = Path(__file__).resolve().parent.parent

# å®šä¹‰å„ä¸ªæ¨¡å‹æ–‡ä»¶çš„è·¯å¾„
CHATGLM_MODEL_PATH = PROJECT_ROOT / "chatglm-ggml.bin"
CHATGLM2_MODEL_PATH = PROJECT_ROOT / "chatglm2-ggml.bin"
CHATGLM3_MODEL_PATH = PROJECT_ROOT / "chatglm3-ggml.bin"
CODEGEEX2_MODEL_PATH = PROJECT_ROOT / "codegeex2-ggml.bin"
BAICHUAN13B_MODEL_PATH = PROJECT_ROOT / "baichuan-13b-chat-ggml.bin"
BAICHUAN2_7B_MODEL_PATH = PROJECT_ROOT / "baichuan2-7b-chat-ggml.bin"
BAICHUAN2_13B_MODEL_PATH = PROJECT_ROOT / "baichuan2-13b-chat-ggml.bin"
INTERNLM7B_MODEL_PATH = PROJECT_ROOT / "internlm-chat-7b-ggml.bin"
INTERNLM20B_MODEL_PATH = PROJECT_ROOT / "internlm-chat-20b-ggml.bin"

# æµ‹è¯• chatglm_cpp æ¨¡å—çš„ç‰ˆæœ¬
def test_chatglm_version():
    print(chatglm_cpp.__version__)

# å®šä¹‰æ£€æŸ¥ç®¡é“çš„å‡½æ•°
def check_pipeline(model_path, prompt, target, gen_kwargs={}):
    # åˆ›å»ºç”¨æˆ·æ¶ˆæ¯åˆ—è¡¨
    messages = [chatglm_cpp.ChatMessage(role="user", content=prompt)]

    # åˆ›å»ºç®¡é“å¯¹è±¡
    pipeline = chatglm_cpp.Pipeline(model_path)
    # èŠå¤©å¹¶è·å–è¾“å‡ºå†…å®¹
    output = pipeline.chat(messages, do_sample=False, **gen_kwargs).content
    # æ–­è¨€è¾“å‡ºå†…å®¹ä¸ç›®æ ‡å†…å®¹ç›¸åŒ
    assert output == target

    # å¦‚æœæ˜¯ CHATGLM3_MODEL_PATH æ¨¡å‹ï¼Œåˆ™è¿›è¡Œç‰¹æ®Šå¤„ç†
    stream_output = pipeline.chat(messages, do_sample=False, stream=True, **gen_kwargs)
    stream_output = "".join([msg.content for msg in stream_output])
    if model_path == CHATGLM3_MODEL_PATH:
        # ä¸º ChatGLM3 è¿›è¡Œç‰¹æ®Šå¤„ç†
        stream_output = stream_output.strip()
    assert stream_output == target

# æµ‹è¯• ChatGLM æ¨¡å‹çš„ç®¡é“
@pytest.mark.skipif(not CHATGLM_MODEL_PATH.exists(), reason="model file not found")
def test_chatglm_pipeline():
    check_pipeline(model_path=CHATGLM_MODEL_PATH, prompt="ä½ å¥½", target="ä½ å¥½ğŸ‘‹ï¼æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ ChatGLM-6Bï¼Œå¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæ¬¢è¿é—®æˆ‘ä»»ä½•é—®é¢˜ã€‚")

# æµ‹è¯• ChatGLM2 æ¨¡å‹çš„ç®¡é“
@pytest.mark.skipif(not CHATGLM2_MODEL_PATH.exists(), reason="model file not found")
def test_chatglm2_pipeline():
    check_pipeline(model_path=CHATGLM2_MODEL_PATH, prompt="ä½ å¥½", target="ä½ å¥½ğŸ‘‹ï¼æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ ChatGLM2-6Bï¼Œå¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæ¬¢è¿é—®æˆ‘ä»»ä½•é—®é¢˜ã€‚")

# æµ‹è¯• ChatGLM3 æ¨¡å‹çš„ç®¡é“
@pytest.mark.skipif(not CHATGLM3_MODEL_PATH.exists(), reason="model file not found")
def test_chatglm3_pipeline():
    # è°ƒç”¨ check_pipeline å‡½æ•°ï¼Œä¼ å…¥æ¨¡å‹è·¯å¾„ã€æç¤ºè¯­å’Œç›®æ ‡æ–‡æœ¬ä½œä¸ºå‚æ•°
    check_pipeline(model_path=CHATGLM3_MODEL_PATH, prompt="ä½ å¥½", target="ä½ å¥½ğŸ‘‹ï¼æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ ChatGLM3-6Bï¼Œå¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæ¬¢è¿é—®æˆ‘ä»»ä½•é—®é¢˜ã€‚")
# æ ‡è®°ä¸ºè·³è¿‡æµ‹è¯•ï¼Œå¦‚æœ CODEGEEX2_MODEL_PATH ä¸å­˜åœ¨åˆ™è·³è¿‡
@pytest.mark.skipif(not CODEGEEX2_MODEL_PATH.exists(), reason="model file not found")
def test_codegeex2_pipeline():
    # è®¾ç½®è¾“å…¥çš„æç¤ºå’Œç›®æ ‡è¾“å‡º
    prompt = "# language: Python\n# write a bubble sort function\n"
    target = """

def bubble_sort(list):
    for i in range(len(list) - 1):
        for j in range(len(list) - 1):
            if list[j] > list[j + 1]:
                list[j], list[j + 1] = list[j + 1], list[j]
    return list


print(bubble_sort([5, 4, 3, 2, 1]))"""
    
    # åˆ›å»º chatglm_cpp.Pipeline å¯¹è±¡
    pipeline = chatglm_cpp.Pipeline(CODEGEEX2_MODEL_PATH)
    # ç”Ÿæˆè¾“å‡ºç»“æœï¼Œç¦ç”¨é‡‡æ ·
    output = pipeline.generate(prompt, do_sample=False)
    # æ–­è¨€è¾“å‡ºç»“æœä¸ç›®æ ‡ç›¸åŒ
    assert output == target

    # ç”Ÿæˆè¾“å‡ºç»“æœï¼Œç¦ç”¨é‡‡æ ·ï¼Œä½¿ç”¨æµå¼è¾“å‡º
    stream_output = pipeline.generate(prompt, do_sample=False, stream=True)
    stream_output = "".join(stream_output)
    # æ–­è¨€æµå¼è¾“å‡ºç»“æœä¸ç›®æ ‡ç›¸åŒ
    assert stream_output == target


# æ ‡è®°ä¸ºè·³è¿‡æµ‹è¯•ï¼Œå¦‚æœ BAICHUAN13B_MODEL_PATH ä¸å­˜åœ¨åˆ™è·³è¿‡
@pytest.mark.skipif(not BAICHUAN13B_MODEL_PATH.exists(), reason="model file not found")
def test_baichuan13b_pipeline():
    # æ£€æŸ¥æŒ‡å®šæ¨¡å‹çš„è¾“å‡ºç»“æœæ˜¯å¦ç¬¦åˆé¢„æœŸ
    check_pipeline(
        model_path=BAICHUAN13B_MODEL_PATH,
        prompt="ä½ å¥½å‘€",
        target="ä½ å¥½ï¼å¾ˆé«˜å…´è§åˆ°ä½ ã€‚è¯·é—®æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ",
        gen_kwargs=dict(repetition_penalty=1.1),
    )


# æ ‡è®°ä¸ºè·³è¿‡æµ‹è¯•ï¼Œå¦‚æœ BAICHUAN2_7B_MODEL_PATH ä¸å­˜åœ¨åˆ™è·³è¿‡
@pytest.mark.skipif(not BAICHUAN2_7B_MODEL_PATH.exists(), reason="model file not found")
def test_baichuan2_7b_pipeline():
    # æ£€æŸ¥æŒ‡å®šæ¨¡å‹çš„è¾“å‡ºç»“æœæ˜¯å¦ç¬¦åˆé¢„æœŸ
    check_pipeline(
        model_path=BAICHUAN2_7B_MODEL_PATH,
        prompt="ä½ å¥½å‘€",
        target="ä½ å¥½ï¼å¾ˆé«˜å…´ä¸ºä½ æœåŠ¡ã€‚è¯·é—®æœ‰ä»€ä¹ˆé—®é¢˜æˆ‘å¯ä»¥å¸®åŠ©ä½ è§£å†³ï¼Ÿ",
        gen_kwargs=dict(repetition_penalty=1.05),
    )


# æ ‡è®°ä¸ºè·³è¿‡æµ‹è¯•ï¼Œå¦‚æœ BAICHUAN2_13B_MODEL_PATH ä¸å­˜åœ¨åˆ™è·³è¿‡
@pytest.mark.skipif(not BAICHUAN2_13B_MODEL_PATH.exists(), reason="model file not found")
def test_baichuan2_13b_pipeline():
    # æ£€æŸ¥æŒ‡å®šæ¨¡å‹çš„è¾“å‡ºç»“æœæ˜¯å¦ç¬¦åˆé¢„æœŸ
    check_pipeline(
        model_path=BAICHUAN2_13B_MODEL_PATH,
        prompt="ä½ å¥½å‘€",
        target="ä½ å¥½ï¼å¾ˆé«˜å…´è§åˆ°ä½ ã€‚è¯·é—®æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ",
        gen_kwargs=dict(repetition_penalty=1.05),
    )


# æ ‡è®°ä¸ºè·³è¿‡æµ‹è¯•ï¼Œå¦‚æœ INTERNLM7B_MODEL_PATH ä¸å­˜åœ¨åˆ™è·³è¿‡
@pytest.mark.skipif(not INTERNLM7B_MODEL_PATH.exists(), reason="model file not found")
def test_internlm7b_pipeline():
    # æ£€æŸ¥æŒ‡å®šæ¨¡å‹çš„è¾“å‡ºç»“æœæ˜¯å¦ç¬¦åˆé¢„æœŸ
    check_pipeline(model_path=INTERNLM7B_MODEL_PATH, prompt="ä½ å¥½", target="ä½ å¥½ï¼Œæœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ")


# æ ‡è®°ä¸ºè·³è¿‡æµ‹è¯•ï¼Œå¦‚æœ INTERNLM20B_MODEL_PATH ä¸å­˜åœ¨åˆ™è·³è¿‡
@pytest.mark.skipif(not INTERNLM20B_MODEL_PATH.exists(), reason="model file not found")
# å®šä¹‰ä¸€ä¸ªæµ‹è¯•å‡½æ•°ï¼Œç”¨äºæµ‹è¯•INTERNLM20Bæ¨¡å‹çš„pipeline
def test_internlm20b_pipeline():
    # è°ƒç”¨check_pipelineå‡½æ•°ï¼Œä¼ å…¥INTERNLM20B_MODEL_PATHä½œä¸ºæ¨¡å‹è·¯å¾„ï¼Œ"ä½ å¥½"ä½œä¸ºè¾“å…¥æç¤ºï¼Œ"ä½ å¥½ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ"ä½œä¸ºç›®æ ‡è¾“å‡º
    check_pipeline(model_path=INTERNLM20B_MODEL_PATH, prompt="ä½ å¥½", target="ä½ å¥½ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ")
```